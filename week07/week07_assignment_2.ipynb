{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Assignment\n",
    "\n",
    "_MkKinney 6.1_\n",
    "\n",
    "This week has been all about getting information off the internet both in structured data formats (CSV, JSON, etc) as well as HTML.  For these exercises, we're going to use two practical examples of fetching data from web pages to show how to use Pandas and BeautifulSoup to extract structured information from the web.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.1 Parsing a list in HTML\n",
    "\n",
    "Go to the Banner Health Price Transparency Page: https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency\n",
    "\n",
    "Notice that there is a list of hospitals and the city they are in.  We want to parse the underlying HTML to create a list of all the hospitals along with which city they're in.\n",
    "\n",
    "```json\n",
    "[\n",
    "    [\"Banner - University Medical Center Phoenix\", \"Arizona\"],\n",
    "    [\"Banner - University Medical Center South \", \"Arizona\"],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "To examine the underlying HTML code, you can use Chrome, right-click, and choose **Inspect**.\n",
    "\n",
    "For reference, the documentation for BeautifulSoup is here: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create a function called **parse_banner(url)** that takes as it's one parameter the URL of the webpage to be parsed for links.  Make sure you include docstrings and a good test case using hte URL provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arizona Banner - University Medical Center Phoenix\n",
      "Arizona Banner - University Medical Center South \n",
      "Arizona Banner - University Medical Center Tucson\n",
      "Arizona Banner Baywood Medical Center \n",
      "Arizona Banner Behavioral Health Hospital\n",
      "Arizona Banner Boswell Medical Center\n",
      "Arizona Banner Casa Grande Medical Center\n",
      "Arizona Banner Del E. Webb Medical Center\n",
      "Arizona Banner Desert Medical Center/Cardon Children's Medical Center  \n",
      "Arizona Banner Estrella Medical Center\n",
      "Arizona Banner Gateway Medical Center/Banner MD Anderson Cancer Center\n",
      "Arizona Banner Goldfield Medical Center  \n",
      "Arizona Banner Heart Hospital\n",
      "Arizona Banner Ironwood Medical Center\n",
      "Arizona Banner Ocotillo Medical Center\n",
      "Arizona Banner Payson Medical Center\n",
      "Arizona Banner Rehabilitation Hospitals\n",
      "Arizona Banner Thunderbird Medical Center\n",
      "Arizona Page Hospital\n",
      "California Banner Lassen Medical Center\n",
      "Colorado Banner Fort Collins Medical Center\n",
      "Colorado McKee Medical Center\n",
      "Colorado North Colorado Medical Center\n",
      "Colorado Sterling Regional Medical Center\n",
      "Colorado East Morgan County Hospital\n",
      "Nebraska Ogallala Community Hospital\n",
      "Nevada Banner Churchill Community Hospital\n",
      "Wyoming Banner Wyoming Medical Center Central Campus\n",
      "Wyoming Banner Wyoming Medical Center East Campus\n",
      "Wyoming Community Hospital\n",
      "Wyoming Washakie Medical Center\n",
      "Wyoming Platte County Memorial Hospital\n",
      "State-Specific Regulations Arizona\n",
      "State-Specific Regulations California\n",
      "State-Specific Regulations Colorado\n",
      "State-Specific Regulations Nebraska\n",
      "State-Specific Regulations Nevada\n",
      "State-Specific Regulations Wyoming\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Note that you'll need to fetch the data using the following syntax to include headers\n",
    "# that make the web server think you're a real web browser.\n",
    "def parse_banner(url)\n",
    "headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\" }\n",
    "response = requests.get('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency', headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "'''\n",
    "This function returns \n",
    ">>> len(parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency')\n",
    "38\n",
    "'''\n",
    "div = soup.find_all('div', {\"class\":\"col-md-8\"})[0]\n",
    "for hospital_list in div.find_all('ul'):\n",
    "    state = hospital_list.previous_sibling.previous_sibling.string\n",
    "    for hospital in hospital_list.find_all('li'):\n",
    "        print(state, hospital.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_banner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-23f2c2e2c347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdoctest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoctest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_docstring_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_banner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_banner' is not defined"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(parse_banner, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banner = parse_banner('https://www.bannerhealth.com/patients/billing/pricing-resources/hospital-price-transparency')\n",
    "assert len(banner)==38, 'Length of result should have been 38, but {} returned.'.format(len(banner))\n",
    "assert banner[0][1]=='Arizona', 'Wrong data found in the first result item: {}'.format(banner[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 33.2 Using a REST API (from GitHub.com)\n",
    "\n",
    "Many websites provide something called a REST API to access information from their site programatically, rather than relying on HTML.  One example is GitHub.com, whose API allows you do to things like \"list all the public repositories for a user.\"\n",
    "\n",
    "The documentation for GitHub.com's REST API can be found here: https://docs.github.com/en/rest/guides/getting-started-with-the-rest-api\n",
    "\n",
    "Create a function called **repo_summary(user)** that takes a GitHub.com user name as it's parameter and retrieves a list of all the repositories you can see for that user.  The specific documentation for the this kind of request can be found here: https://docs.github.com/en/rest/reference/repos#list-repositories-for-a-user. Make sure your function is well documented with a docstring and includes a simple test to verify that you get back 12 repositories when querying for the repositories for user **paulboal**.\n",
    "\n",
    "I've provided a related example to help you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example -- this example of code shows how to get basic information on the user paulboal\n",
    "# For your solution, make sure you meet the requirements in the instructions above.\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://api.github.com/users/paulboal')\n",
    "data = response.json()\n",
    "\n",
    "print('This information is about {}. His website is {}.'.format(data.get('login'), data.get('blog')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code Here\n",
    "def repo_summary(user):\n",
    "    '''\n",
    "    This function retrives the number of repositories for a user given their username on Github.\n",
    "    >>> len(repo_summary('paulboul'))\n",
    "    12\n",
    "    '''\n",
    "    response = requests.get('https://api.github.com/users/paulboal/repos')\n",
    "    data = response.json()\n",
    "    user_repos = []\n",
    "    for i in data:\n",
    "        user_repos.append(i['name'])\n",
    "    \n",
    "    return user_repos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(repo_summary, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = repo_summary('paulboal')\n",
    "assert len(repos)==12, 'Expecing 12, but {} were found'.format(len(repos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 33.3 Find Something of Your Own\n",
    "\n",
    "Do some web searches and find an HTML page with some data that is interesting to something you're studying.  You can extract and parse that information using either BeautifulSoup or Pandas.  If you're using Pandas, then do something interesting to format and structure your data.  If you're using BeautifulSoup, you'll just need to do the work of parsing the data out of HTML -- that's hard enough!\n",
    "\n",
    "You don't need to build this as a function.  Just use notebook cells as I've done above.  You will be graded based on _style_.  Use variable names that make sense for your problem / solution. Cleanup anything you don't need before you submit your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_highest-grossing_films')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = tables[0]\n",
    "\n",
    "#Dropping redundant information such as references and peak using '.drop' function to make it neater and easier to read.\n",
    "movie_data.drop([\"Reference(s)\", \"Peak\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---\n",
    "\n",
    "## Check your work above\n",
    "\n",
    "If you didn't get them all correct, take a few minutes to think through those that aren't correct.\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Follow the instruction on the prompt below to either ssave and submit your work, or continue working.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a=input('''\n",
    "Are you ready to submit your work?\n",
    "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
    "2. Type \"yes\" or \"no\" below\n",
    "3. Press Enter\n",
    "\n",
    "''')\n",
    "\n",
    "if a=='yes':\n",
    "    !git add week07_assignment_2.ipynb\n",
    "    !git commit -a -m \"Submitting the week 7 programming exercises\"\n",
    "    !git push\n",
    "else:\n",
    "    print('''\n",
    "    \n",
    "OK. We can wait.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
